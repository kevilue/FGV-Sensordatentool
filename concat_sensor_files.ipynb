{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd678dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read configs (required!)\n",
    "\n",
    "import tomllib\n",
    "with open(\"settings.toml\", \"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "\n",
    "with open(\"sensors.toml\", \"rb\") as f:\n",
    "    sensors = tomllib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformSensorFile(df_dict: dict, sensor_name: str, datetime_col=False):\n",
    "    \"\"\"Split the three existing columns into eight with sensor info, location and separate columns for time data.\"\"\"\n",
    "    df_dict[\"df\"].drop(df_dict[\"idxcol\"], axis=1, inplace=True)\n",
    "    if not datetime_col: df_dict[\"df\"][\"Datum\"] = df_dict[\"df\"][df_dict[\"timecol\"]].dt.date\n",
    "    else: df_dict[\"df\"][\"Datum\"] = df_dict[\"df\"][df_dict[\"timecol\"]]\n",
    "    df_dict[\"df\"][\"Jahr\"] = df_dict[\"df\"][df_dict[\"timecol\"]].dt.year\n",
    "    df_dict[\"df\"][\"Monat\"] = df_dict[\"df\"][df_dict[\"timecol\"]].dt.month\n",
    "    df_dict[\"df\"][\"Tag\"] = df_dict[\"df\"][df_dict[\"timecol\"]].dt.day\n",
    "    df_dict[\"df\"][\"Uhrzeit\"] = df_dict[\"df\"][df_dict[\"timecol\"]].dt.time\n",
    "    df_dict[\"df\"][\"Sensor\"] = sensor_name\n",
    "    df_dict[\"df\"][\"Standort\"] = sensors[sensor_name][\"location\"]\n",
    "    df_dict[\"df\"].drop(df_dict[\"timecol\"], axis=1, inplace=True)\n",
    "    df_dict[\"df\"].rename(columns={df_dict[\"tmpcol\"]: \"Temperatur\"}, inplace=True)\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read excel files\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "\n",
    "path_to_files = r\"./data\"\n",
    "save_path = \"all_data.csv\"\n",
    "\n",
    "def concat_sensor_files(path_to_files: str, save_path=None) -> None | pd.DataFrame :\n",
    "    \"\"\"Concatenate all given csv files collected from sensors into new ones.\"\"\"\n",
    "    data_paths = glob.glob(path_to_files+\"\\\\FGV_*.xlsx\", recursive=True)\n",
    "    print(\"Found\", len(data_paths), \"files\")\n",
    "\n",
    "    sensors_chunks = {key: [] for key in sensors.keys()}\n",
    "\n",
    "    if save_path is not None: stime = time.perf_counter()\n",
    "\n",
    "    for idx, file in enumerate(data_paths):\n",
    "        sensor_name = re.search(r\"FGV_\\d+\", file).group()\n",
    "        if not sensor_name in sensors.keys():\n",
    "            raise(NameError(f\"Trying to read sensor {sensor_name} which is not defined in sensors.toml\"))\n",
    "        print(\"Reading sensor\", sensor_name, f\"({idx+1}/{len(data_paths)})\")\n",
    "        df = pd.read_excel(file)\n",
    "\n",
    "        idxcol, timecol, tmpcol = None, None, None\n",
    "        for idx, col in enumerate(df.columns):\n",
    "            # print(idx, col)\n",
    "            if config[\"names\"][\"index_column\"] in col:\n",
    "                idxcol = col\n",
    "                # print(\"Found index column:\", col)\n",
    "            elif config[\"names\"][\"timestamp_column\"] in col:\n",
    "                timecol = col\n",
    "                # print(\"Found timestamp column:\", col)\n",
    "            elif config[\"names\"][\"temperature_column\"] in col:\n",
    "                tmpcol = col\n",
    "                # print(\"Found temperature column:\", col)\n",
    "            else: raise(IndexError(f\"Found unknown column: {col}\"))\n",
    "\n",
    "        df[timecol] = pd.to_datetime(df[timecol], format=config[\"formats\"][\"time_format\"])\n",
    "        df.sort_values(timecol, ascending=False, inplace=True)\n",
    "        # sensors_chunks[sensor_name].append({\"df\": df, \"idxcol\": idxcol, \"timecol\": timecol, \"tmpcol\": tmpcol})\n",
    "        df = transformSensorFile({\"df\": df, \"idxcol\": idxcol, \"timecol\": timecol, \"tmpcol\": tmpcol}, sensor_name, datetime_col=True)[\"df\"]\n",
    "        sensors_chunks[sensor_name].append(df)\n",
    "\n",
    "    # Use topmost entry\n",
    "    searchfunc = lambda x: x[\"Datum\"].iloc[0]\n",
    "    # Sort chunks after newest newest entry\n",
    "    for key in sensors_chunks.keys():\n",
    "        sensors_chunks[key].sort(key=searchfunc, reverse=True) # Newest at top\n",
    "        for idx, x in enumerate(sensors_chunks[key]):\n",
    "            if save_path is not None: print(f\"{idx}: {searchfunc(x)}\", end=\" \")\n",
    "        if save_path is not None: print(f\"(Sensor {key})\")\n",
    "        sensors_chunks[key] = pd.concat(sensors_chunks[key])\n",
    "\n",
    "    all_sensors_chunks = [sensors_chunks[key] for key in sensors_chunks.keys()]\n",
    "    all_sensors_chunks = pd.concat(all_sensors_chunks)\n",
    "    # sensors_chunks should now contain all the sensor files, sorted for all sensors read with newest data at the top\n",
    "\n",
    "    if save_path is not None:\n",
    "        with open(save_path, \"w\") as f:\n",
    "            all_sensors_chunks.to_csv(f, index=False)\n",
    "\n",
    "        ttime = time.perf_counter() - stime\n",
    "        print(f\"Finished in {ttime:.2f}s\")\n",
    "\n",
    "    else: return all_sensors_chunks\n",
    "\n",
    "# concat_sensor_files(path_to_files, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571073c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading old file...\n",
      "Done (0.21s). Concatenating new files...\n",
      "Found 16 files\n",
      "Reading sensor FGV_01 (1/16)\n",
      "Reading sensor FGV_02 (2/16)\n",
      "Reading sensor FGV_02 (3/16)\n",
      "Reading sensor FGV_03 (4/16)\n",
      "Reading sensor FGV_03 (5/16)\n",
      "Reading sensor FGV_04 (6/16)\n",
      "Reading sensor FGV_05 (7/16)\n",
      "Reading sensor FGV_06 (8/16)\n",
      "Reading sensor FGV_07 (9/16)\n",
      "Reading sensor FGV_08 (10/16)\n",
      "Reading sensor FGV_08 (11/16)\n",
      "Reading sensor FGV_09 (12/16)\n",
      "Reading sensor FGV_09 (13/16)\n",
      "Reading sensor FGV_10 (14/16)\n",
      "Reading sensor FGV_10 (15/16)\n",
      "Reading sensor FGV_11 (16/16)\n",
      "Done (5.07s). Combining...\n",
      "Done (5.20s). Saving...\n",
      "Done combining files, took 7.20s\n"
     ]
    }
   ],
   "source": [
    "def append_sensor_files(path_to_files: str, old_file: str, save_path: str):\n",
    "    \"\"\"Concatenate an existing file with new ones.\"\"\"\n",
    "    stime = time.perf_counter()\n",
    "    print(\"Reading old file...\")\n",
    "    base = pd.read_csv(old_file)\n",
    "    print(f\"Done ({time.perf_counter()-stime:.2f}s). Concatenating new files...\")\n",
    "    new = concat_sensor_files(path_to_files=path_to_files)\n",
    "    print(f\"Done ({time.perf_counter()-stime:.2f}s). Combining...\")\n",
    "    combined = pd.concat([new, base])\n",
    "    print(f\"Done ({time.perf_counter()-stime:.2f}s). Saving...\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        combined.to_csv(f, index=False)\n",
    "\n",
    "    print(f\"Done combining files, took {time.perf_counter()-stime:.2f}s\")\n",
    "\n",
    "append_sensor_files(path_to_files, save_path, \"all_duplicate.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
